name: Performance Test Pipeline (k6 + JMeter + Gatling)

on:
  workflow_dispatch:
    inputs:
      run_k6:
        description: 'Run k6 performance tests'
        required: false
        default: true
        type: boolean
      run_jmeter:
        description: 'Run JMeter performance tests'
        required: false
        default: true
        type: boolean
      run_gatling:
        description: 'Run Gatling performance tests'
        required: false
        default: true
        type: boolean
      target_url:
        description: 'Target URL for performance tests'
        required: false
        default: 'http://localhost:5173'
        type: string
      test_duration:
        description: 'Test duration in minutes'
        required: false
        default: '5'
        type: string
      concurrent_users:
        description: 'Number of concurrent users'
        required: false
        default: '10'
        type: string

jobs:
  setup-environment:
    name: Setup Test Environment
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build application
        run: npm run build

      - name: Start application
        run: |
          npm run preview &
          sleep 10
          echo "Application started at http://localhost:4173"

      - name: Wait for application to be ready
        run: |
          for i in {1..30}; do
            if curl -f http://localhost:4173; then
              echo "Application is ready"
              break
            fi
            echo "Waiting for application... ($i/30)"
            sleep 2
          done

  performance-tests-k6:
    name: Performance Tests (k6)
    runs-on: ubuntu-latest
    needs: setup-environment
    if: ${{ github.event.inputs.run_k6 == 'true' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install k6
        run: |
          sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Run k6 performance tests
        run: npm run test:performance:k6
        env:
          TEST_TARGET_URL: ${{ github.event.inputs.target_url }}
          TEST_DURATION: ${{ github.event.inputs.test_duration }}
          CONCURRENT_USERS: ${{ github.event.inputs.concurrent_users }}

      - name: Upload k6 results
        uses: actions/upload-artifact@v3
        with:
          name: k6-performance-results
          path: ./reports/k6-results-*.json

      - name: Generate k6 report
        run: |
          mkdir -p ./reports/k6
          k6 run --out json=./reports/k6/k6-results.json tests/performance/k6-load-test.js

  performance-tests-jmeter:
    name: Performance Tests (JMeter)
    runs-on: ubuntu-latest
    needs: setup-environment
    if: ${{ github.event.inputs.run_jmeter == 'true' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Java
        uses: actions/setup-java@v3
        with:
          distribution: 'temurin'
          java-version: '11'

      - name: Download JMeter
        run: |
          wget https://archive.apache.org/dist/jmeter/binaries/apache-jmeter-5.4.3.tgz
          tar -xzf apache-jmeter-5.4.3.tgz
          echo "JMETER_HOME=$PWD/apache-jmeter-5.4.3" >> $GITHUB_ENV

      - name: Run JMeter performance tests
        run: |
          $JMETER_HOME/bin/jmeter -n -t tests/performance/jmeter-load-test.jmx \
            -JTEST_TARGET_URL=${{ github.event.inputs.target_url }} \
            -JTEST_DURATION=${{ github.event.inputs.test_duration }} \
            -JCONCURRENT_USERS=${{ github.event.inputs.concurrent_users }} \
            -l reports/jmeter-results.jtl \
            -e -o reports/jmeter-html-report

      - name: Upload JMeter results
        uses: actions/upload-artifact@v3
        with:
          name: jmeter-performance-results
          path: |
            reports/jmeter-results.jtl
            reports/jmeter-html-report/

  performance-tests-gatling:
    name: Performance Tests (Gatling)
    runs-on: ubuntu-latest
    needs: setup-environment
    if: ${{ github.event.inputs.run_gatling == 'true' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Java
        uses: actions/setup-java@v3
        with:
          distribution: 'temurin'
          java-version: '11'

      - name: Download Gatling
        run: |
          wget https://repo1.maven.org/maven2/io/gatling/highcharts/gatling-charts-highcharts-bundle/3.9.5/gatling-charts-highcharts-bundle-3.9.5-bundle.zip
          unzip gatling-charts-highcharts-bundle-3.9.5-bundle.zip
          echo "GATLING_HOME=$PWD/gatling-charts-highcharts-bundle-3.9.5" >> $GITHUB_ENV

      - name: Create Gatling test
        run: |
          mkdir -p $GATLING_HOME/user-files/simulations
          cat > $GATLING_HOME/user-files/simulations/LoadTest.scala << 'EOF'
          package simulations
          
          import io.gatling.core.Predef._
          import io.gatling.http.Predef._
          
          class LoadTest extends Simulation {
            val httpProtocol = http
              .baseUrl(sys.env.getOrElse("TEST_TARGET_URL", "http://localhost:5173"))
              .acceptHeader("text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8")
              .doNotTrackHeader("1")
              .acceptLanguageHeader("en-US,en;q=0.5")
              .acceptEncodingHeader("gzip, deflate")
              .userAgentHeader("Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20100101 Firefox/31.0")
          
            val scn = scenario("Load Test")
              .exec(http("Home Page")
                .get("/")
                .check(status.is(200)))
              .pause(1)
              .exec(http("Health Check")
                .get("/health")
                .check(status.is(200)))
          
            setUp(
              scn.inject(
                rampUsers(sys.env.getOrElse("CONCURRENT_USERS", "10").toInt)
                  .during(sys.env.getOrElse("TEST_DURATION", "5").toInt.minutes)
              )
            ).protocols(httpProtocol)
          }
          EOF

      - name: Run Gatling performance tests
        run: |
          $GATLING_HOME/bin/gatling.sh -s LoadTest -rf reports/gatling

      - name: Upload Gatling results
        uses: actions/upload-artifact@v3
        with:
          name: gatling-performance-results
          path: reports/gatling/

  test-results-parser:
    name: Parse and Combine Performance Test Results
    runs-on: ubuntu-latest
    needs: [performance-tests-k6, performance-tests-jmeter, performance-tests-gatling]
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Download test results
        uses: actions/download-artifact@v3
        with:
          path: ./reports/

      - name: Parse test results
        run: |
          node -e "
          const { TestResultsParser } = require('./src/utils/testResultsParser.js');
          const parser = new TestResultsParser();
          
          // Parse results from each framework
          const k6Results = parser.parseResults('k6', 'performance', './reports/k6/k6-results.json');
          const jmeterResults = parser.parseResults('jmeter', 'performance', './reports/jmeter-results.jtl');
          const gatlingResults = parser.parseResults('gatling', 'performance', './reports/gatling/simulation.log');
          
          // Generate unified report
          const unifiedReport = parser.generateUnifiedReport([k6Results, jmeterResults, gatlingResults]);
          
          // Save unified report
          require('fs').writeFileSync('./reports/unified-performance-test-report.json', JSON.stringify(unifiedReport, null, 2));
          console.log('Unified performance test report generated');
          "

      - name: Upload unified test report
        uses: actions/upload-artifact@v3
        with:
          name: unified-performance-test-report
          path: ./reports/unified-performance-test-report.json

  notify-results:
    name: Notify Performance Test Results
    runs-on: ubuntu-latest
    needs: [performance-tests-k6, performance-tests-jmeter, performance-tests-gatling, test-results-parser]
    if: always()
    steps:
      - name: Download unified test report
        uses: actions/download-artifact@v3
        with:
          name: unified-performance-test-report

      - name: Parse results for notification
        id: results
        run: |
          if [ -f "./unified-performance-test-report.json" ]; then
            TOTAL_TESTS=$(jq '.summary.total' unified-performance-test-report.json)
            PASSED_TESTS=$(jq '.summary.passed' unified-performance-test-report.json)
            FAILED_TESTS=$(jq '.summary.failed' unified-performance-test-report.json)
            SUCCESS_RATE=$(echo "scale=1; $PASSED_TESTS * 100 / $TOTAL_TESTS" | bc)
            AVG_RESPONSE_TIME=$(jq '.performance.avgResponseTime' unified-performance-test-report.json)
            ERROR_RATE=$(jq '.performance.errorRate' unified-performance-test-report.json)
            
            echo "total=$TOTAL_TESTS" >> $GITHUB_OUTPUT
            echo "passed=$PASSED_TESTS" >> $GITHUB_OUTPUT
            echo "failed=$FAILED_TESTS" >> $GITHUB_OUTPUT
            echo "success_rate=$SUCCESS_RATE" >> $GITHUB_OUTPUT
            echo "avg_response_time=$AVG_RESPONSE_TIME" >> $GITHUB_OUTPUT
            echo "error_rate=$ERROR_RATE" >> $GITHUB_OUTPUT
          else
            echo "total=0" >> $GITHUB_OUTPUT
            echo "passed=0" >> $GITHUB_OUTPUT
            echo "failed=0" >> $GITHUB_OUTPUT
            echo "success_rate=0" >> $GITHUB_OUTPUT
            echo "avg_response_time=0" >> $GITHUB_OUTPUT
            echo "error_rate=0" >> $GITHUB_OUTPUT
          fi

      - name: Notify Slack
        if: ${{ steps.results.outputs.failed > 0 || steps.results.outputs.error_rate > 5 }}
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          text: |
            Performance Test Pipeline Failed! 
            Total Requests: ${{ steps.results.outputs.total }}
            Passed: ${{ steps.results.outputs.passed }}
            Failed: ${{ steps.results.outputs.failed }}
            Success Rate: ${{ steps.results.outputs.success_rate }}%
            Avg Response Time: ${{ steps.results.outputs.avg_response_time }}ms
            Error Rate: ${{ steps.results.outputs.error_rate }}%
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

      - name: Notify Slack Success
        if: ${{ steps.results.outputs.failed == 0 && steps.results.outputs.error_rate <= 5 }}
        uses: 8398a7/action-slack@v3
        with:
          status: success
          text: |
            Performance Test Pipeline Passed! 
            Total Requests: ${{ steps.results.outputs.total }}
            Passed: ${{ steps.results.outputs.passed }}
            Success Rate: ${{ steps.results.outputs.success_rate }}%
            Avg Response Time: ${{ steps.results.outputs.avg_response_time }}ms
            Error Rate: ${{ steps.results.outputs.error_rate }}%
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
