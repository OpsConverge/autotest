name: CI/CD Pipeline 1 - Vitest + Supertest + Playwright + k6

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        default: 'test'
        type: choice
        options:
        - test
        - staging
        - production
      run_all_tests:
        description: 'Run all test types'
        required: false
        default: true
        type: boolean
      run_unit_tests:
        description: 'Run unit tests only'
        required: false
        default: false
        type: boolean
      run_integration_tests:
        description: 'Run integration tests only'
        required: false
        default: false
        type: boolean
      run_api_tests:
        description: 'Run API tests only'
        required: false
        default: false
        type: boolean
      run_e2e_tests:
        description: 'Run E2E tests only'
        required: false
        default: false
        type: boolean
      run_performance_tests:
        description: 'Run performance tests only'
        required: false
        default: false
        type: boolean

env:
  NODE_VERSION: '18'
  TEST_ENVIRONMENT_URL: ${{ secrets.TEST_ENVIRONMENT_URL }}
  TEST_ENVIRONMENT_IP: ${{ secrets.TEST_ENVIRONMENT_IP }}
  TEST_USER_EMAIL: ${{ secrets.TEST_USER_EMAIL }}
  TEST_USER_PASSWORD: ${{ secrets.TEST_USER_PASSWORD }}

jobs:
  # Job 1: Code Quality & Linting
  code-quality:
    name: Code Quality & Linting
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run ESLint
        run: npm run lint

  # Job 2: Unit Tests (Vitest)
  unit-tests:
    name: Unit Tests (Vitest)
    runs-on: ubuntu-latest
    needs: code-quality
    if: ${{ github.event.inputs.run_all_tests == 'true' || github.event.inputs.run_unit_tests == 'true' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run unit tests with Vitest
        run: npm run test:unit

      - name: Generate coverage report
        run: npm run test:ci

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage/coverage-final.json
          flags: unit-vitest
          name: unit-coverage-vitest

  # Job 3: Integration Tests (Supertest)
  integration-tests:
    name: Integration Tests (Supertest)
    runs-on: ubuntu-latest
    needs: code-quality
    if: ${{ github.event.inputs.run_all_tests == 'true' || github.event.inputs.run_integration_tests == 'true' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run integration tests with Supertest
        run: npm run test:integration:supertest

  # Job 4: API Tests (Supertest)
  api-tests:
    name: API Tests (Supertest)
    runs-on: ubuntu-latest
    needs: code-quality
    if: ${{ github.event.inputs.run_all_tests == 'true' || github.event.inputs.run_api_tests == 'true' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run API tests with Supertest
        run: npm run test:api:supertest

  # Job 5: Deploy to Test Environment
  deploy-test:
    name: Deploy to Test Environment
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, api-tests]
    if: ${{ github.event.inputs.run_all_tests == 'true' || github.event.inputs.run_e2e_tests == 'true' || github.event.inputs.run_performance_tests == 'true' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build frontend
        run: npm run build

      - name: Deploy to EC2 Test Environment
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ env.TEST_ENVIRONMENT_IP }}
          username: ubuntu
          key: ${{ secrets.EC2_SSH_KEY }}
          script: |
            cd /opt/autotest
            git pull origin main
            docker-compose -f docker-compose.test.yml down
            docker-compose -f docker-compose.test.yml build --no-cache
            docker-compose -f docker-compose.test.yml up -d
            docker-compose -f docker-compose.test.yml exec backend node scripts/migrate.js
            echo "Deployment completed successfully"

      - name: Wait for deployment
        run: |
          sleep 30
          echo "Waiting for services to be ready..."

  # Job 6: E2E Tests (Playwright)
  e2e-tests:
    name: E2E Tests (Playwright)
    runs-on: ubuntu-latest
    needs: deploy-test
    if: ${{ github.event.inputs.run_all_tests == 'true' || github.event.inputs.run_e2e_tests == 'true' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: npx playwright install --with-deps

      - name: Setup test environment variables
        run: |
          echo "TEST_TARGET_URL=${{ env.TEST_ENVIRONMENT_URL }}" >> $GITHUB_ENV
          echo "TEST_API_URL=${{ env.TEST_ENVIRONMENT_URL }}/api" >> $GITHUB_ENV

      - name: Run E2E tests with Playwright
        run: |
          npx playwright test --reporter=junit
        env:
          TEST_TARGET_URL: ${{ env.TEST_ENVIRONMENT_URL }}
          TEST_API_URL: ${{ env.TEST_ENVIRONMENT_URL }}/api
          TEST_USER_EMAIL: ${{ env.TEST_USER_EMAIL }}
          TEST_USER_PASSWORD: ${{ env.TEST_USER_PASSWORD }}

      - name: Upload Playwright test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: playwright-report
          path: playwright-report/
          retention-days: 30

  # Job 7: Performance Tests (k6)
  performance-tests:
    name: Performance Tests (k6)
    runs-on: ubuntu-latest
    needs: deploy-test
    if: ${{ github.event.inputs.run_all_tests == 'true' || github.event.inputs.run_performance_tests == 'true' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup k6
        uses: grafana/k6-action@v0.3.0
        with:
          filename: tests/performance/k6-load-test.js
          flags: --out json=reports/k6-results.json

      - name: Setup test environment variables
        run: |
          echo "TEST_TARGET_URL=${{ env.TEST_ENVIRONMENT_URL }}" >> $GITHUB_ENV
          echo "TEST_API_URL=${{ env.TEST_ENVIRONMENT_URL }}/api" >> $GITHUB_ENV

      - name: Run performance tests with k6
        run: |
          k6 run tests/performance/k6-load-test.js --out json=reports/k6-results.json
        env:
          TEST_TARGET_URL: ${{ env.TEST_ENVIRONMENT_URL }}
          TEST_API_URL: ${{ env.TEST_ENVIRONMENT_URL }}/api

      - name: Upload k6 test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: k6-results
          path: reports/k6-results.json
          retention-days: 30

  # Job 8: Test Results Summary
  test-results:
    name: Test Results Summary (Pipeline 1)
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, api-tests, e2e-tests, performance-tests]
    if: always()
    steps:
      - name: Generate test summary
        run: |
          echo "## Test Results Summary - Pipeline 1" >> $GITHUB_STEP_SUMMARY
          echo "### Unit Tests (Vitest): ${{ needs.unit-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "### Integration Tests (Supertest): ${{ needs.integration-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "### API Tests (Supertest): ${{ needs.api-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "### E2E Tests (Playwright): ${{ needs.e2e-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "### Performance Tests (k6): ${{ needs.performance-tests.result }}" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.unit-tests.result }}" == "success" ] && [ "${{ needs.integration-tests.result }}" == "success" ] && [ "${{ needs.api-tests.result }}" == "success" ] && [ "${{ needs.e2e-tests.result }}" == "success" ] && [ "${{ needs.performance-tests.result }}" == "success" ]; then
            echo "✅ All tests passed in Pipeline 1!" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Some tests failed in Pipeline 1. Please check the logs above." >> $GITHUB_STEP_SUMMARY
          fi
